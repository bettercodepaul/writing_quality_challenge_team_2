{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_run_type = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', None)\n",
    "if kaggle_run_type:\n",
    "    DATA_PATH = \"/kaggle/input/linking-writing-processes-to-writing-quality\"\n",
    "else:\n",
    "    DATA_PATH = \"../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pl.read_csv(f\"{DATA_PATH}/train_logs.csv\")\n",
    "scores = pl.read_csv(f\"{DATA_PATH}/train_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safediv(dividend, divisor, fill_expr=pl.lit(0)):\n",
    "    div_expr = (\n",
    "        pl.when(divisor.ne(0))\n",
    "        .then(dividend.truediv(divisor))\n",
    "        .otherwise(fill_expr)\n",
    "    )\n",
    "    return(div_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = (\n",
    "    logs\n",
    "    # only consider text changing activities\n",
    "    .filter(pl.col(\"activity\").ne(\"Nonproduction\"))\n",
    "    # split text changes of Replace activity into replace_remove and replace_input\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"activity\").eq(\"Replace\"))\n",
    "        .then(pl.col(\"text_change\").str.split(\" => \"))\n",
    "        .list.to_struct(fields=[\"replace_remove\", \"replace_input\"])\n",
    "        .alias(\"Replace\")\n",
    "    )\n",
    "    .unnest(\"Replace\")\n",
    "    .with_columns(\n",
    "        # merge text changes of Input, Paste + Replace(Input)\n",
    "        pl.when(pl.col(\"activity\").eq(\"Input\") | pl.col(\"activity\").eq(\"Paste\"))\n",
    "        .then(pl.col(\"text_change\"))\n",
    "        .otherwise(pl.col(\"replace_input\"))\n",
    "        .alias(\"input\"),\n",
    "        # merge text changes of Remove/Cut + Replace(Remove)\n",
    "        pl.when(pl.col(\"activity\").eq(\"Remove/Cut\"))\n",
    "        .then(pl.col(\"text_change\"))\n",
    "        .otherwise(pl.col(\"replace_remove\"))\n",
    "        .alias(\"remove\")\n",
    "    )\n",
    "    # concat all text changes for each essay\n",
    "    .group_by(\"id\")\n",
    "    .agg(\n",
    "        pl.col(\"input\").filter(pl.col(\"input\").is_not_null()).str.concat(\"\"),\n",
    "        pl.col(\"remove\").filter(pl.col(\"remove\").is_not_null()).str.concat(\"\")\n",
    "    )\n",
    "    .melt(id_vars=\"id\")\n",
    "    # count characters and punctuation marks\n",
    "    .with_columns(\n",
    "        pl.col(\"value\").str.len_bytes().alias(\"total_chars\"),\n",
    "        pl.col(\"value\").str.count_matches(\"q\").alias(\"word_chars\"),\n",
    "        pl.col(\"value\").str.count_matches(\"\\.\").alias(\"full_stops\"),\n",
    "        pl.col(\"value\").str.count_matches(\",\").alias(\"commas\"),\n",
    "        pl.col(\"value\").str.count_matches(\"\\n\").alias(\"line_breaks\"),\n",
    "        pl.col(\"value\").str.count_matches(\"-\").alias(\"hyphens\"),\n",
    "        pl.col(\"value\").str.count_matches(\"\\?\").alias(\"question_marks\"),\n",
    "        pl.col(\"value\").str.count_matches(\";\").alias(\"semicolons\"),\n",
    "        pl.col(\"value\").str.count_matches(\":\").alias(\"colons\"),\n",
    "        pl.col(\"value\").str.count_matches(\"!\").alias(\"exclamation_marks\"),\n",
    "    )\n",
    "    # subtract counts of removed text from counts of input text\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"variable\").eq(\"remove\"))\n",
    "        .then(pl.exclude(\"id\", \"variable\", \"value\").mul(-1))\n",
    "        .otherwise(pl.exclude(\"id\", \"variable\", \"value\"))\n",
    "    )\n",
    "    .group_by(\"id\")\n",
    "    .agg(pl.exclude(\"variable\", \"value\").sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_stats = (\n",
    "    logs\n",
    "    .sort(\"event_id\")\n",
    "    .group_by(\"id\")\n",
    "    .agg(\n",
    "        pl.col(\"word_count\").last(),\n",
    "        (pl.col(\"up_time\").max() - pl.col(\"down_time\").min()).alias(\"write_duration\"),\n",
    "        pl.col(\"event_id\").count().alias(\"event_count\"),\n",
    "    )\n",
    "    .join(scores, on=\"id\")\n",
    "    .join(counts, on=\"id\")\n",
    "    .with_columns(\n",
    "        (pl.col(\"full_stops\")+pl.col(\"question_marks\")+pl.col(\"exclamation_marks\")+pl.col(\"colons\")).alias(\"sentence_count\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        safediv(pl.col(\"word_chars\"), pl.col(\"word_count\")).alias(\"avg_word_length\"),\n",
    "        safediv(pl.col(\"word_chars\"), pl.col(\"sentence_count\")).alias(\"avg_chars_per_sentence\"),\n",
    "        safediv(pl.col(\"word_count\"), pl.col(\"sentence_count\")).alias(\"avg_words_per_sentence\"),\n",
    "        ((pl.col(\"total_chars\") - pl.col(\"word_chars\"))/pl.col(\"total_chars\")).alias(\"non_word_char_pct\"),\n",
    "        safediv(pl.col(\"word_count\"), pl.col(\"line_breaks\")).alias(\"avg_words_per_paragraph\"),\n",
    "        safediv(pl.col(\"total_chars\"), pl.col(\"line_breaks\")).alias(\"avg_chars_per_paragraph\"),\n",
    "        safediv(pl.col(\"commas\"), pl.col(\"sentence_count\")).alias(\"avg_commas_per_sentence\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_stats.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"n_estimators\" : 100,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(features):\n",
    "    # Define the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        #(\"scaler\", StandardScaler()),  # Normalize the features\n",
    "        #(\"knn\", KNeighborsRegressor())  # Use KNN model\n",
    "        #(\"gb\", HistGradientBoostingRegressor())  # Use Gradient Boosting\n",
    "        (\"rf\", RandomForestRegressor())\n",
    "        #(\"lm\", LinearRegression())\n",
    "        #(\"lgb\", lgb.LGBMRegressor(**lightgbm_params, verbose=-1))\n",
    "    ])\n",
    "\n",
    "    # Split into features and target\n",
    "    #X = essay_stats.select(pl.exclude(\"score\", \"id\")).to_numpy()\n",
    "    X = essay_stats.select(features).to_numpy()\n",
    "    y = essay_stats.select(\"score\").to_numpy()\n",
    "\n",
    "    # Cross validate the pipeline using 4 folds\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=4, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    # Print the mean score and standard deviation\n",
    "    return(cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_best_feature(current_features, current_score):\n",
    "    features = [col for col in essay_stats.columns if (col not in current_features) & (col!=\"id\") & (col!=\"score\")]\n",
    "    next_best_feature = None\n",
    "    next_best_score = current_score\n",
    "    for col in features:\n",
    "        score = (cv(current_features + [col]) + cv(current_features + [col]))/2\n",
    "        if score > next_best_score:\n",
    "            next_best_feature = col\n",
    "            next_best_score = score\n",
    "    return (next_best_feature, next_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_features(current_features = [], current_score = -1.0247):\n",
    "    while True:\n",
    "        next_best_feature, next_best_score = get_next_best_feature(current_features, current_score)\n",
    "        if next_best_feature is None:\n",
    "            break\n",
    "        current_features.append(next_best_feature)\n",
    "        improvement = (current_score - next_best_score)/current_score\n",
    "        print(f\"Added '{next_best_feature}' with score {next_best_score:.4f} improving by {improvement:.2%}\")\n",
    "        current_score = next_best_score\n",
    "    return(current_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\"commas\", \"word_chars\", \"avg_chars_per_sentence\", \"non_word_char_pct\", \"event_count\", \"avg_word_length\", \"line_breaks\"]\n",
    "base_score = -0.6400\n",
    "try_features(base_features, base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
